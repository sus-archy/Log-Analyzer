# LogMind AI

A local-first log observability platform with AI-powered insights.

## Features

- **Log Ingestion**: Automatically ingest logs from local folders (JSONL, CSV, text formats)
- **Template Mining**: Drain-based algorithm extracts reusable log templates with parameters
- **Semantic Search**: FAISS-powered vector similarity search using Ollama embeddings
- **AI Chat**: Ask questions about your logs with grounded, citation-backed answers
- **ML Analytics**: Real machine learning for anomaly detection, classification, and threat detection
- **Predictive Analytics**: Time-series forecasting for system health prediction
- **Web UI**: Modern Next.js interface with Explorer, Templates, and Chat views

## Documentation

ğŸ“š See the [docs/](docs/) folder for detailed documentation:

| Document | Description |
|----------|-------------|
| [Project Documentation](PROJECT_DOCUMENTATION.md) | Full Project Documentation |
| [Code Documentation](Code_Dodumentation.md) | Code Explanation |
| [ML Documentation](ML_DOCUMENTATION.md) | Machine learning module guide |
| [Architecture](ARCHITECTURE.md) | System design and architecture |

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Next.js UI                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Log Explorerâ”‚  â”‚  Templates  â”‚  â”‚      Chat Panel         â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚ HTTP
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      FastAPI Backend                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Ingest  â”‚ â”‚  Logs    â”‚ â”‚ Templates â”‚ â”‚ Semantic + Chat    â”‚ â”‚
â”‚  â”‚ Service â”‚ â”‚  Service â”‚ â”‚  Service  â”‚ â”‚ Services           â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚       â”‚           â”‚             â”‚                   â”‚           â”‚
â”‚  â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                     Storage Layer                         â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚ â”‚
â”‚  â”‚  â”‚                 SQLite Database                       â”‚â”‚ â”‚
â”‚  â”‚  â”‚  â€¢ log_templates  â€¢ logs_stream  â€¢ template_vectors   â”‚â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚ â”‚
â”‚  â”‚  â”‚                 FAISS Index                           â”‚â”‚ â”‚
â”‚  â”‚  â”‚  â€¢ Vector similarity search (IndexFlatIP)             â”‚â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Ollama (Local)                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  nemotron-mini      â”‚  â”‚  nomic-embed-text                â”‚ â”‚
â”‚  â”‚  (Chat Model)       â”‚  â”‚  (Embedding Model)               â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Quick Start

### Prerequisites

1. **Python 3.11+**
2. **Node.js 18+**
3. **Ollama** - Install from https://ollama.ai

### Setup

```bash
# 1. Install dependencies
make install

# 2. Start Ollama and pull required models
ollama serve  # In a separate terminal
make setup-models

# 3. Create data directory
make init

# 4. Run the application
make run
```

The UI will be available at http://localhost:3000

### Alternative: Manual Setup

```bash
# Backend
cd apps/api
pip install -r requirements.txt
uvicorn app.main:app --host 0.0.0.0 --port 8000

# Frontend (in another terminal)
cd apps/ui
npm install
npm run dev
```

## Configuration

Environment variables (set in `.env` or shell):

| Variable | Default | Description |
|----------|---------|-------------|
| `LOGS_FOLDER` | `./Logs` | Path to logs folder for ingestion |
| `SQLITE_PATH` | `./data/logmind.sqlite` | SQLite database path |
| `FAISS_INDEX_PATH` | `./data/faiss_index.bin` | FAISS index path |
| `OLLAMA_URL` | `http://localhost:11434` | Ollama API endpoint |
| `OLLAMA_EMBED_MODEL` | `nomic-embed-text` | Embedding model name |
| `OLLAMA_CHAT_MODEL` | `qwen2.5:3b` | Chat model name |
| `EMBED_DIM` | `768` | Embedding dimension |
| `AUTH_ENABLED` | `false` | Enable JWT authentication |
| `SECRET_KEY` | (random) | JWT signing key |
| `CORS_ORIGINS` | `["http://localhost:3000"]` | Allowed CORS origins |
| `RATE_LIMIT_CHAT` | `20/minute` | Rate limit for chat endpoint |
| `DB_POOL_SIZE` | `5` | Database connection pool size |

## API Endpoints

### Health
- `GET /health` - Health check (includes Ollama status)

### Authentication (when enabled)
- `POST /auth/token` - Get JWT access token
- `GET /auth/me` - Get current user info
- `GET /auth/status` - Check auth configuration

### Ingest
- `POST /ingest` - Ingest logs from configured folder

### Logs
- `GET /logs` - Query logs with filters
- `GET /logs/services` - List distinct services
- `GET /logs/stats/quick` - Quick statistics

### Templates
- `GET /templates/top` - Get top templates by occurrence
- `GET /templates/{hash}` - Get template details
- `POST /templates/embed` - Embed all pending templates

### Semantic Search
- `POST /semantic/search` - Search templates by semantic similarity

### Chat (rate limited)
- `POST /chat` - Ask questions about logs with AI

### Metrics
- `GET /metrics/performance` - Performance metrics
- `GET /metrics/security` - Security analysis
- `GET /metrics/services/health` - Service health status

## Project Structure

```
â”œâ”€â”€ apps/
â”‚   â”œâ”€â”€ api/                    # FastAPI backend
â”‚   â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”‚   â”œâ”€â”€ core/           # Config, logging, security, rate limiting
â”‚   â”‚   â”‚   â”œâ”€â”€ llm/            # Ollama client
â”‚   â”‚   â”‚   â”œâ”€â”€ parsers/        # Log parsing, Drain miner
â”‚   â”‚   â”‚   â”œâ”€â”€ routes/         # API routes (with auth)
â”‚   â”‚   â”‚   â”œâ”€â”€ schemas/        # Pydantic models (with validation)
â”‚   â”‚   â”‚   â”œâ”€â”€ services/       # Business logic (metrics, security)
â”‚   â”‚   â”‚   â”œâ”€â”€ storage/        # Database (with connection pool), repos
â”‚   â”‚   â”‚   â””â”€â”€ vector/         # FAISS index
â”‚   â”‚   â”œâ”€â”€ tests/              # Unit tests
â”‚   â”‚   â””â”€â”€ requirements.txt
â”‚   â””â”€â”€ ui/                     # Next.js frontend
â”‚       â”œâ”€â”€ src/
â”‚       â”‚   â”œâ”€â”€ app/            # Pages
â”‚       â”‚   â”œâ”€â”€ components/     # React components (with ErrorBoundary)
â”‚       â”‚   â”œâ”€â”€ lib/            # API client, Zustand store
â”‚       â”‚   â””â”€â”€ types.ts        # TypeScript types
â”‚       â””â”€â”€ package.json
â”œâ”€â”€ Logs/                       # Log files for ingestion
â”œâ”€â”€ data/                       # SQLite DB, FAISS index
â”œâ”€â”€ scripts/                    # Setup and utility scripts
â””â”€â”€ Makefile
```

## Development

```bash
# Run in development mode with hot reload
make dev

# Run tests
make test

# Run smoke tests (requires running backend)
make smoke

# Lint code
make lint
```

## Usage Guide

### 1. Ingest Logs

Place your log files in the `Logs/` folder (supports `.log`, `.txt`, `.jsonl`, `.csv`). Then:

```bash
# Via API
curl -X POST http://localhost:8000/ingest

# Or use the "Ingest Logs" button in the UI
```

### 2. Explore Logs

Open the **Explorer** tab to browse logs:
- Filter by service, severity, time range
- Click a row to expand and see details
- Search within results

### 3. View Templates

Open the **Templates** tab to see extracted patterns:
- Templates group similar logs together
- Parameters are shown as `<*>` placeholders
- Click a template to see recent occurrences

### 4. Embed Templates

Before using semantic search or chat, embed the templates:

```bash
# Via API
curl -X POST http://localhost:8000/templates/embed

# Or use the "Embed Templates" button in the UI
```

### 5. Chat with Logs

Open the **Chat** tab and ask questions like:
- "What errors occurred in the last hour?"
- "Why are there connection failures?"
- "Summarize the issues for this service"

The AI provides grounded answers with citations to specific templates and logs.

## License

MIT
